{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "\n",
    "import time\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D # Conv2D, Input, Flatten, MaxPooling2D, UpSampling2D, concatenate, Cropping2D, Reshape, BatchNormalization\n",
    "from keras.utils import HDF5Matrix\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0516 18:54:13.875253 140072729698432 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/utils/comparams.py:1: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.load_data import load_data\n",
    "from utils.preprocess import DataGenerator\n",
    "from utils.comparams import calculate_auc, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(image, now=True, fig_size=(5, 5)):\n",
    "    image = image.astype(np.float32)\n",
    "    m, M = image.min(), image.max()\n",
    "    if fig_size != None:\n",
    "        plt.rcParams['figure.figsize'] = (fig_size[0], fig_size[1])\n",
    "    plt.imshow((image - m) / (M - m), cmap='gray')\n",
    "    plt.axis('off')\n",
    "    if now == True:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = './data/macenko'\n",
    "data_dir = './data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test_true = load_data(data_dir, purpose='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indexes\n",
    "test_id = np.arange(len(x_test))\n",
    "\n",
    "# create a useful dictionary structures\n",
    "partition = {}\n",
    "partition['test'] = test_id\n",
    "    \n",
    "test_labels = {str(i) : y_test_true[i].flatten()[0] for i in test_id}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculate AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.array(y_test_true).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = np.array([p[1] for p in preds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.9129782979784034\n",
      "tf auc: [0.9129074, 0.9129074]\n"
     ]
    }
   ],
   "source": [
    "calculate_auc(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19 Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.9086748213509703\n",
      "tf auc: [0.90866363, 0.90866363]\n"
     ]
    }
   ],
   "source": [
    "true_labels = np.array(y_test_true).flatten()\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG19 Predictions with lr 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.9062592216085712\n",
      "tf auc: [0.90621924, 0.90621924]\n"
     ]
    }
   ],
   "source": [
    "true_labels = np.array(y_test_true).flatten()\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19 with learningrate 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.8990378027888102\n",
      "tf auc: [0.89904654, 0.89904654]\n"
     ]
    }
   ],
   "source": [
    "true_labels = np.array(y_test_true).flatten()\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inception \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to save the best model\n",
    "file_dir = './Model/lor_acc'\n",
    "pred_file_dir = './Preds'\n",
    "model_name = 'InceptionResNetV2_best_acc_model'\n",
    "network_filepath = os.path.join(file_dir, model_name + '.h5') #_limitless\n",
    "\n",
    "# Define batch size.\n",
    "batch_size = 128\n",
    "\n",
    "# Parameters for generators\n",
    "params = {\n",
    "    'dim': (224, 224),\n",
    "    'batch_size': batch_size,\n",
    "    'n_classes': 2,\n",
    "    'shuffle': False\n",
    "}\n",
    "\n",
    "# Generators\n",
    "test_generator = DataGenerator(partition['test'], x_test, test_labels, **params)\n",
    "\n",
    "from tensorflow import metrics, local_variables_initializer\n",
    "from keras.backend import get_session\n",
    "from sklearn.metrics import roc_auc_score as skroc\n",
    "import tensorflow as tf\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = metrics.auc(y_true, y_pred)[1]\n",
    "    get_session().run(local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "\n",
    "dependencies = {\n",
    "    'auc': auc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0516 18:54:52.948099 140072729698432 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0516 18:54:52.962135 140072729698432 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0516 18:54:52.964756 140072729698432 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0516 18:54:52.982017 140072729698432 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0516 18:54:53.354661 140072729698432 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0516 18:54:53.523482 140072729698432 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0516 18:54:53.890093 140072729698432 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "incres = InceptionResNetV2(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "x = incres.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "y = Dense(2, activation='softmax')(x) # sigmoid instead of softmax to have independent probabilities\n",
    "\n",
    "model = Model(inputs=incres.input, outputs=y)\n",
    "\n",
    "# Train only the top layer\n",
    "for layer in incres.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(network_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0516 18:57:07.364081 140072729698432 deprecation.py:323] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.48340424219819855\n",
      "tf auc: [0.46961868, 0.46961868]\n"
     ]
    }
   ],
   "source": [
    "# whole data normal data predictions inception resnet\n",
    "true_labels = np.array(y_test_true).flatten()[:len(preds)]\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels) # without beta lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(pred_file_dir, 'preds_inception-resnet.csv'), 'w') as f:\n",
    "    f.write(\"case, prediction1, prediction2\")\n",
    "    for i, p in enumerate(preds):\n",
    "        f.write(str(i) + ',' + str(p[0]) + ',' + str(p[1]) + '\\n')\n",
    "        \n",
    "        \n",
    "with open(os.path.join(pred_file_dir, 'preds_inception-resnet1_sub.csv'), 'w') as f:\n",
    "    f.write(\"case, prediction\\n\")\n",
    "    for i, p in enumerate(preds):\n",
    "        f.write(str(i) + ',' + str(p[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG16 Whole data lorenzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to save the best model\n",
    "file_dir = './Model/lor_acc'\n",
    "pred_file_dir = './Preds'\n",
    "model_name = 'vgg16_best_acc_model'\n",
    "network_filepath = os.path.join(file_dir, model_name + '.h5') #_limitless\n",
    "\n",
    "# Define batch size.\n",
    "batch_size = 128\n",
    "\n",
    "# Parameters for generators\n",
    "params = {\n",
    "    'dim': (224, 224),\n",
    "    'batch_size': batch_size,\n",
    "    'n_classes': 2,\n",
    "    'shuffle': False\n",
    "}\n",
    "\n",
    "# Generators\n",
    "test_generator = DataGenerator(partition['test'], x_test, test_labels, **params)\n",
    "\n",
    "from tensorflow import metrics, local_variables_initializer\n",
    "from keras.backend import get_session\n",
    "from sklearn.metrics import roc_auc_score as skroc\n",
    "import tensorflow as tf\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = metrics.auc(y_true, y_pred)[1]\n",
    "    get_session().run(local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "\n",
    "dependencies = {\n",
    "    'auc': auc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "x = vgg16.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "y = Dense(2, activation='softmax')(x) # sigmoid instead of softmax to have independent probabilities\n",
    "\n",
    "model = Model(inputs=vgg16.input, outputs=y)\n",
    "\n",
    "# Train only the top layer\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(network_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.8803514321789897\n",
      "tf auc: [0.88006735, 0.88006735]\n"
     ]
    }
   ],
   "source": [
    "# whole data normal data predictions vgg16\n",
    "true_labels = np.array(y_test_true).flatten()[:len(preds)]\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels) # without beta lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(pred_file_dir, 'vgg16-whole_data_lore.csv'), 'w') as f:\n",
    "    f.write(\"case, prediction1, prediction2\")\n",
    "    for i, p in enumerate(preds):\n",
    "        f.write(str(i) + ',' + str(p[0]) + ',' + str(p[1]) + '\\n')\n",
    "        \n",
    "        \n",
    "with open(os.path.join(pred_file_dir, 'vgg16-whole_data_lore_sub.csv'), 'w') as f:\n",
    "    f.write(\"case, prediction\\n\")\n",
    "    for i, p in enumerate(preds):\n",
    "        f.write(str(i) + ',' + str(p[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## xception Whole data lorenzo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to save the best model\n",
    "file_dir = './Model/lor_acc'\n",
    "pred_file_dir = './Preds'\n",
    "model_name = 'Xception_best_acc_model'\n",
    "network_filepath = os.path.join(file_dir, model_name + '.h5') #_limitless\n",
    "\n",
    "# Define batch size.\n",
    "batch_size = 128\n",
    "\n",
    "# Parameters for generators\n",
    "params = {\n",
    "    'dim': (224, 224),\n",
    "    'batch_size': batch_size,\n",
    "    'n_classes': 2,\n",
    "    'shuffle': False\n",
    "}\n",
    "\n",
    "# Generators\n",
    "test_generator = DataGenerator(partition['test'], x_test, test_labels, **params)\n",
    "\n",
    "from tensorflow import metrics, local_variables_initializer\n",
    "from keras.backend import get_session\n",
    "from sklearn.metrics import roc_auc_score as skroc\n",
    "import tensorflow as tf\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = metrics.auc(y_true, y_pred)[1]\n",
    "    get_session().run(local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "\n",
    "dependencies = {\n",
    "    'auc': auc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "inc = Xception(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "\n",
    "x = inc.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(256, activation='relu')(x)\n",
    "#x = Dropout(0.5)(x)\n",
    "\n",
    "y = Dense(2, activation='softmax')(x) # sigmoid instead of softmax to have independent probabilities\n",
    "\n",
    "model = Model(inputs=inc.input, outputs=y)\n",
    "\n",
    "# Train only the top layer\n",
    "for layer in inc.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(network_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.5802331657388251\n",
      "tf auc: [0.5800938, 0.5800938]\n"
     ]
    }
   ],
   "source": [
    "# whole data normal data predictions xception\n",
    "true_labels = np.array(y_test_true).flatten()[:len(preds)]\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels) # without beta lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(pred_file_dir, 'xception-whole_data_lore.csv'), 'w') as f:\n",
    "    f.write(\"case, prediction1, prediction2\")\n",
    "    for i, p in enumerate(preds):\n",
    "        f.write(str(i) + ',' + str(p[0]) + ',' + str(p[1]) + '\\n')\n",
    "        \n",
    "        \n",
    "with open(os.path.join(pred_file_dir, 'xception-whole_data_lore_sub.csv'), 'w') as f:\n",
    "    f.write(\"case, prediction\\n\")\n",
    "    for i, p in enumerate(preds):\n",
    "        f.write(str(i) + ',' + str(p[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG19  Changable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory to save the best model\n",
    "file_dir = './Model'\n",
    "pred_file_dir = './Preds'\n",
    "model_name = 'vgg16_model_50K'\n",
    "# 'stain_norm_VGG19_model_10K'    \n",
    "network_filepath = os.path.join(file_dir, model_name + '.h5') #_limitless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size.\n",
    "batch_size = 128\n",
    "\n",
    "# Parameters for generators\n",
    "params = {\n",
    "    'dim': (224, 224),\n",
    "    'batch_size': batch_size,\n",
    "    'n_classes': 2,\n",
    "    'shuffle': False\n",
    "}\n",
    "\n",
    "# Generators\n",
    "test_generator = DataGenerator(partition['test'], x_test, test_labels, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import metrics, local_variables_initializer\n",
    "from keras.backend import get_session\n",
    "from sklearn.metrics import roc_auc_score as skroc\n",
    "import tensorflow as tf\n",
    "\n",
    "def auc(y_true, y_pred):\n",
    "    auc = metrics.auc(y_true, y_pred)[1]\n",
    "    get_session().run(local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dependencies = {\n",
    "    'auc': auc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0516 15:33:25.314671 140371061563520 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0516 15:33:25.328767 140371061563520 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0516 15:33:25.344115 140371061563520 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0516 15:33:25.530491 140371061563520 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0516 15:33:25.530972 140371061563520 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0516 15:33:26.078083 140371061563520 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0516 15:33:26.131880 140371061563520 deprecation.py:323] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0516 15:33:26.239979 140371061563520 deprecation.py:323] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = load_model(network_filepath, custom_objects=dependencies)\n",
    "# model = model_from_json(open(network_filepath).read())\n",
    "# model.load_weights(os.path.join(os.path.dirname(network_filepath)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.8356441909319363\n",
      "tf auc: [0.8354149, 0.8354149]\n"
     ]
    }
   ],
   "source": [
    "# 50K normal data predictions\n",
    "true_labels = np.array(y_test_true).flatten()[:len(preds)]\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels) # without beta lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.8442031326366719\n",
      "tf auc: [0.8434149, 0.8434149]\n"
     ]
    }
   ],
   "source": [
    "# 100K normal data predictions\n",
    "true_labels = np.array(y_test_true).flatten()[:len(preds)]\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels) # without beta lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.9037854756619346\n",
      "tf auc: [0.90377045, 0.90377045]\n"
     ]
    }
   ],
   "source": [
    "# Stain Norm 10000 predictions\n",
    "true_labels = np.array(y_test_true).flatten()[:len(preds)]\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels) # without beta lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.9129782979784034\n",
      "tf auc: [0.9129074, 0.9129074]\n"
     ]
    }
   ],
   "source": [
    "true_labels = np.array(y_test_true).flatten()\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels) # without beta lr=0.0001 learning rate reduction changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.8974235205864627\n",
      "tf auc: [0.8974233, 0.8974233]\n"
     ]
    }
   ],
   "source": [
    "true_labels = np.array(y_test_true).flatten()\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels) # 0.00007"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
