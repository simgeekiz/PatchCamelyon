{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "\n",
    "import time\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import HDF5Matrix\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, Flatten, Concatenate \n",
    "# Conv2D, Input, Flatten, MaxPooling2D, UpSampling2D, concatenate, Cropping2D, Reshape, BatchNormalization\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0608 14:27:56.774016 140002190921856 deprecation_wrapper.py:119] From ../utils/comparams.py:1: The name tf.local_variables_initializer is deprecated. Please use tf.compat.v1.local_variables_initializer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils.load_data import load_data\n",
    "from utils.preprocess import DataGenerator\n",
    "from utils.comparams import calculate_auc, auc\n",
    "from utils.callbacks import PlotCurves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arch_2_net():\n",
    "    \n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    x = vgg16.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    y = Dense(2, activation='softmax')(x) # sigmoid instead of softmax to have independent probabilities\n",
    "    model = Model(inputs=vgg16.input, outputs=y)\n",
    "    \n",
    "    # Train only the top layer\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_arch_4_net():\n",
    "    \n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    x = vgg16.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    y = Dense(2, activation='softmax')(x) # sigmoid instead of softmax to have independent probabilities\n",
    "    model = Model(inputs=vgg16.input, outputs=y)\n",
    "    \n",
    "    # Train only the top layer\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_arch_5_net():\n",
    "    \n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    x = vgg16.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    y = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=vgg16.input, outputs=y)\n",
    "    \n",
    "    # Train only the top layer\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_arch_6_net():\n",
    "    \n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    x = vgg16.output\n",
    "    out1 = GlobalMaxPooling2D()(x)\n",
    "    out2 = GlobalAveragePooling2D()(x)\n",
    "    out3 = Flatten()(x)\n",
    "    out = Concatenate(axis=-1)([out1, out2, out3])\n",
    "    out = Dropout(0.5)(out)\n",
    "    y = Dense(2, activation='softmax')(out) # sigmoid instead of softmax to have independent probabilities\n",
    "\n",
    "    model = Model(inputs=vgg16.input, outputs=y)\n",
    "    \n",
    "    # Train only the top layer\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_arch_8_net():\n",
    "    \n",
    "    vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(224,224,3))\n",
    "    x = vgg16.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    y = Dense(2, activation='softmax')(x)\n",
    "    model = Model(inputs=vgg16.input, outputs=y)\n",
    "    \n",
    "    # Train only the top layer\n",
    "    for layer in vgg16.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../data'\n",
    "\n",
    "x_test, y_test_true = load_data(data_dir, purpose='test')#, norm='macenko')\n",
    "\n",
    "# indexes\n",
    "test_id = np.arange(len(x_test))\n",
    "\n",
    "# create a useful dictionary structures\n",
    "partition = {}\n",
    "partition['test'] = test_id\n",
    "    \n",
    "test_labels = {str(i) : y_test_true[i].flatten()[0] for i in test_id}\n",
    "\n",
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = '../Model'\n",
    "model_name = 'vgg16_model_bin_cross_arch_6_lr_0_0001'    \n",
    "network_filepath = os.path.join(file_dir, model_name + '.h5') #_limitless\n",
    "\n",
    "# Define batch size.\n",
    "batch_size = 128\n",
    "\n",
    "# Parameters for generators\n",
    "params = {\n",
    "    'dim': (224, 224),\n",
    "    'batch_size': batch_size,\n",
    "    'n_classes': 2,\n",
    "    'shuffle': False\n",
    "}\n",
    "\n",
    "# Generators\n",
    "test_generator = DataGenerator(partition['test'], x_test, test_labels, **params)\n",
    "\n",
    "dependencies = {\n",
    "    'auc': auc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0608 14:14:22.642821 139825971679360 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0608 14:14:22.653675 139825971679360 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0608 14:14:22.668997 139825971679360 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0608 14:14:22.791591 139825971679360 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:131: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0608 14:14:22.792000 139825971679360 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0608 14:14:22.796088 139825971679360 deprecation.py:506] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0608 14:14:23.403938 139825971679360 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0608 14:14:23.409960 139825971679360 deprecation_wrapper.py:119] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3378: The name tf.nn.sigmoid_cross_entropy_with_logits is deprecated. Please use tf.nn.sigmoid_cross_entropy_with_logits instead.\n",
      "\n",
      "W0608 14:14:23.411590 139825971679360 deprecation.py:323] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/tensorflow/python/ops/nn_impl.py:179: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0608 14:14:23.426738 139825971679360 deprecation_wrapper.py:119] From ../utils/comparams.py:9: The name tf.metrics.auc is deprecated. Please use tf.compat.v1.metrics.auc instead.\n",
      "\n",
      "W0608 14:14:23.473994 139825971679360 deprecation.py:323] From /home/aorus/workspaces/simge/PatchCamelyon/.env/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py:808: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(network_filepath, custom_objects=dependencies)\n",
    "\n",
    "preds = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.9059770755204435\n",
      "tf auc: [0.9058783, 0.9058783]\n"
     ]
    }
   ],
   "source": [
    "##### Calculate AUC \n",
    "true_labels = np.array(y_test_true).flatten()\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "calculate_auc(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEST ACC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = '../Model/weights'\n",
    "model_name = 'vgg16_model_bin_cross_arch_6_lr_0_0001best_acc_model'\n",
    "network_filepath = os.path.join(file_dir, model_name + '.h5') #_limitless\n",
    "\n",
    "# Define batch size.\n",
    "batch_size = 128\n",
    "\n",
    "# Parameters for generators\n",
    "params = {\n",
    "    'dim': (224, 224),\n",
    "    'batch_size': batch_size,\n",
    "    'n_classes': 2,\n",
    "    'shuffle': False\n",
    "}\n",
    "\n",
    "# Generators\n",
    "test_generator = DataGenerator(partition['test'], x_test, test_labels, **params)\n",
    "\n",
    "dependencies = {\n",
    "    'auc': auc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /scratch/sekiz/PatchCamelyon/.env/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /scratch/sekiz/PatchCamelyon/.env/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "model = build_arch_6_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(network_filepath)\n",
    "\n",
    "preds = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.9122874781567099\n",
      "WARNING:tensorflow:From /scratch/sekiz/PatchCamelyon/.env/lib/python3.5/site-packages/tensorflow/python/ops/metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /scratch/sekiz/PatchCamelyon/.env/lib/python3.5/site-packages/tensorflow/python/ops/metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "tf auc: [0.0010676592, 0.9122108]\n"
     ]
    }
   ],
   "source": [
    "# whole data normal data predictions inception resnet\n",
    "true_labels = np.array(y_test_true).flatten()[:len(preds)]\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels) # without beta lr=0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BEST AUC MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = '../Model/weights'\n",
    "model_name = 'vgg16_model_bin_cross_arch_6_lr_0_0001best_auc_model'\n",
    "network_filepath = os.path.join(file_dir, model_name + '.h5') #_limitless\n",
    "\n",
    "# Define batch size.\n",
    "batch_size = 128\n",
    "\n",
    "# Parameters for generators\n",
    "params = {\n",
    "    'dim': (224, 224),\n",
    "    'batch_size': batch_size,\n",
    "    'n_classes': 2,\n",
    "    'shuffle': False\n",
    "}\n",
    "\n",
    "# Generators\n",
    "test_generator = DataGenerator(partition['test'], x_test, test_labels, **params)\n",
    "\n",
    "dependencies = {\n",
    "    'auc': auc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_arch_6_net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(network_filepath)\n",
    "\n",
    "preds = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.9059770513060522\n",
      "tf auc: [0.90587854, 0.90587854]\n"
     ]
    }
   ],
   "source": [
    "# whole data normal data predictions inception resnet\n",
    "true_labels = np.array(y_test_true).flatten()[:len(preds)]\n",
    "\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "\n",
    "calculate_auc(true_labels, pred_labels) # without beta lr=0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
