{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "\n",
    "import time\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import Model, load_model, model_from_json\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import HDF5Matrix\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, Dropout, GlobalAveragePooling2D, GlobalMaxPooling2D, Flatten, Concatenate \n",
    "# Conv2D, Input, Flatten, MaxPooling2D, UpSampling2D, concatenate, Cropping2D, Reshape, BatchNormalization\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_data import load_data\n",
    "from utils.preprocess import DataGenerator\n",
    "from utils.comparams import calculate_auc, auc\n",
    "from utils.callbacks import PlotCurves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_test(model_path, data_dir='../data/macenko/', epoch=15, batch_size=128):\n",
    "    \n",
    "    x_test, y_test_true = load_data(data_dir, purpose='test', norm='macenko')\n",
    "    \n",
    "    # indexes\n",
    "    test_id = np.arange(len(x_test))\n",
    "\n",
    "    partition = {}\n",
    "    partition['test'] = test_id\n",
    "\n",
    "    test_labels = {str(i) : y_test_true[i].flatten()[0] for i in test_id}\n",
    "\n",
    "    # Parameters for generators\n",
    "    params = {\n",
    "        'dim': (96, 96),\n",
    "        'batch_size': batch_size,\n",
    "        'n_classes': 2,\n",
    "        'aug': False,\n",
    "        'shuffle': False\n",
    "    }\n",
    "\n",
    "    # Generators\n",
    "    test_generator = DataGenerator(partition['test'], x_test, test_labels, **params)\n",
    "\n",
    "    model = load_model(model_path, custom_objects={'auc': auc})\n",
    "\n",
    "    preds = model.predict_generator(test_generator)\n",
    "\n",
    "    true_labels = np.array(y_test_true).flatten()\n",
    "    pred_labels = np.array([p[1] for p in preds])\n",
    "    calculate_auc(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32768"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '../data'\n",
    "\n",
    "x_test, y_test_true = load_data(data_dir, purpose='test', norm='macenko')\n",
    "\n",
    "# indexes\n",
    "test_id = np.arange(len(x_test))\n",
    "\n",
    "# create a useful dictionary structures\n",
    "partition = {}\n",
    "partition['test'] = test_id\n",
    "    \n",
    "test_labels = {str(i) : y_test_true[i].flatten()[0] for i in test_id}\n",
    "\n",
    "len(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size.\n",
    "batch_size = 128\n",
    "\n",
    "# Parameters for generators\n",
    "params = {\n",
    "    'dim': (224, 224),\n",
    "    'batch_size': batch_size,\n",
    "    'n_classes': 2,\n",
    "    'aug': False,\n",
    "    'shuffle': False\n",
    "}\n",
    "\n",
    "# Generators\n",
    "test_generator = DataGenerator(partition['test'], x_test, test_labels, **params)\n",
    "\n",
    "dependencies = {\n",
    "    'auc': auc\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network_filepath = '../Model/vgg16_model_bin_cross_arch_8_lr_0_001_inp96_first10ep/vgg16_model_bin_cross_arch_8_lr_0_001_inp96_epoch_10.h5' \n",
    "# network_filepath = '../Model/vgg16_model_bin_cross_arch_8_lr_0_001_inp96_10ep20ep/vgg16_model_bin_cross_arch_8_lr_0_001_inp96_epoch_5.h5' \n",
    "network_filepath = '../Model/vgg16_model_bin_cross_arch_8_lr_0_001_inp224/vgg16_model_bin_cross_arch_8_lr_0_001_inp224_epoch_1.h5' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(network_filepath, custom_objects=dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.9093410523895604\n",
      "tf auc: [0.0, 0.9093172]\n"
     ]
    }
   ],
   "source": [
    "## vgg16_model_bin_cross_arch_8_lr_0_001_inp224_epoch_1\n",
    "true_labels = np.array(y_test_true).flatten()\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "calculate_auc(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn auc: 0.8929814519587576\n",
      "tf auc: [0.0, 0.8929175]\n"
     ]
    }
   ],
   "source": [
    "## 10ep20ep/vgg16_model_bin_cross_arch_8_lr_0_001_inp96_epoch_5\n",
    "true_labels = np.array(y_test_true).flatten()\n",
    "pred_labels = np.array([p[1] for p in preds])\n",
    "calculate_auc(true_labels, pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
